# Graphiti MCP Server Environment Configuration

# Neo4j Database Configuration
# These settings are used to connect to your Neo4j database
NEO4J_URI=neo4j://192.168.31.150:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=granite-life-bonanza-sunset-lagoon-1071

# Ollama Configuration (local LLM)
# Using Ollama instead of OpenAI for local processing
# OPENAI_API_KEY=abc  # Dummy key for Ollama
# OPENAI_BASE_URL=http://192.168.31.134:11434/v1/
# MODEL_NAME=deepseek-r1:latest
# EMBEDDER_MODEL_NAME=mxbai-embed-large:latest
# EMBEDDING_DIM=1024

# OpenAI API Configuration (disabled)
OPENAI_API_KEY=
MODEL_NAME=gpt-4.1-mini
EMBEDDER_MODEL_NAME=text-embedding-3-small
EMBEDDING_DIM=1536

# Optional: Group ID for namespacing graph data
# GROUP_ID=my_project

# Optional: Path configuration for Docker
# PATH=/root/.local/bin:${PATH}

# Optional: Memory settings for Neo4j (used in Docker Compose)
# NEO4J_server_memory_heap_initial__size=512m
# NEO4J_server_memory_heap_max__size=1G
# NEO4J_server_memory_pagecache_size=512m

# Azure OpenAI configuration
# Optional: Only needed for Azure OpenAI endpoints
# AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint_here
# AZURE_OPENAI_API_VERSION=2025-01-01-preview
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-gpt-4o-mini-deployment
# AZURE_OPENAI_EMBEDDING_API_VERSION=2023-05-15
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-3-large-deployment
# AZURE_OPENAI_USE_MANAGED_IDENTITY=false
