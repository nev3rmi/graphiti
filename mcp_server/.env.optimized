# ============================================================================
# Graphiti MCP Server Environment Configuration (Optimized)
# ============================================================================
# This file configures the MCP server for optimal Ollama integration
# Copy this to .env and customize for your environment

# ============================================================================
# CORE CONFIGURATION
# ============================================================================

# Neo4j Database Connection
NEO4J_URI=neo4j://192.168.31.150:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=granite-life-bonanza-sunset-lagoon-1071

# Ollama Local LLM Configuration  
OPENAI_API_KEY=abc  # Dummy key (required by OpenAI client)
OPENAI_BASE_URL=http://192.168.31.134:11434/v1/
MODEL_NAME=deepseek-r1:latest
EMBEDDER_MODEL_NAME=mxbai-embed-large:latest
EMBEDDING_DIM=1024

# Server Configuration
GROUP_ID=default
SEMAPHORE_LIMIT=10

# ============================================================================
# PERFORMANCE OPTIMIZATION
# ============================================================================

# Concurrency Settings
# Reduce if you experience rate limiting, increase for better performance
# SEMAPHORE_LIMIT=5   # Conservative (slower but more stable)
# SEMAPHORE_LIMIT=15  # Aggressive (faster but may hit limits)

# Temperature Settings (for LLM responses)
# TEMPERATURE=0.0     # Deterministic (default)
# TEMPERATURE=0.3     # Slightly creative
# TEMPERATURE=0.7     # More creative

# ============================================================================
# ALTERNATIVE CONFIGURATIONS
# ============================================================================

# OpenAI Configuration (uncomment to use instead of Ollama)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1/
# MODEL_NAME=gpt-4o-mini
# EMBEDDER_MODEL_NAME=text-embedding-3-small
# EMBEDDING_DIM=1536

# Azure OpenAI Configuration (uncomment to use Azure)
# AZURE_OPENAI_ENDPOINT=your_azure_endpoint_here
# AZURE_OPENAI_API_VERSION=2024-10-21
# AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-3-small
# AZURE_OPENAI_USE_MANAGED_IDENTITY=false

# ============================================================================
# DOCKER AND NETWORKING
# ============================================================================

# MCP Server Host (for Docker)
MCP_SERVER_HOST=0.0.0.0

# Neo4j Memory Settings (for Docker Compose)
NEO4J_server_memory_heap_initial__size=512m
NEO4J_server_memory_heap_max__size=1G
NEO4J_server_memory_pagecache_size=512m

# ============================================================================
# DEVELOPMENT AND DEBUGGING
# ============================================================================

# Logging Level (uncomment for debugging)
# LOG_LEVEL=DEBUG
# LOG_LEVEL=INFO

# Enable/Disable Features
# CUSTOM_ENTITIES=false
# DESTROY_GRAPH_ON_START=false

# ============================================================================
# NETWORK CONFIGURATION EXAMPLES
# ============================================================================

# Local Ollama (same machine)
# OPENAI_BASE_URL=http://localhost:11434/v1/

# Local Ollama (different machine on LAN)
# OPENAI_BASE_URL=http://192.168.1.100:11434/v1/

# Local Ollama (Docker container)
# OPENAI_BASE_URL=http://ollama:11434/v1/

# Local Neo4j
# NEO4J_URI=neo4j://localhost:7687

# Remote Neo4j
# NEO4J_URI=neo4j://your-neo4j-server:7687

# ============================================================================
# RECOMMENDED MODEL COMBINATIONS
# ============================================================================

# Option 1: Balanced Performance (Current Configuration)
# MODEL_NAME=deepseek-r1:latest
# EMBEDDER_MODEL_NAME=mxbai-embed-large:latest
# EMBEDDING_DIM=1024

# Option 2: High Performance (Requires more resources)
# MODEL_NAME=llama3.2:latest
# EMBEDDER_MODEL_NAME=nomic-embed-text:latest
# EMBEDDING_DIM=768

# Option 3: Low Resource (Faster but less capable)
# MODEL_NAME=deepseek-r1:1.5b
# EMBEDDER_MODEL_NAME=all-minilm:latest
# EMBEDDING_DIM=384

# ============================================================================
# SECURITY NOTES
# ============================================================================
# 
# 1. Keep this file secure and don't commit real API keys to version control
# 2. Use strong passwords for Neo4j in production
# 3. Consider using environment-specific .env files (.env.dev, .env.prod)
# 4. For production, consider using secrets management systems
# 5. Regularly rotate API keys and passwords
#
# ============================================================================